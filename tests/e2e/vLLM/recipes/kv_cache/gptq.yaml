quant_stage:
  quant_modifiers:
    QuantizationModifier:
      kv_cache_scheme:
        {num_bits: 8, type: float, symmetric: true, strategy: tensor}
    GPTQModifier:
      sequential_update: false
      ignore: ["lm_head", "re:vision_tower.*", "re:multi_modal_projector.*", "re:visual.*", "re:vision_model.*"]
      config_groups:
          group_0:
              weights:
                  num_bits: 4
                  type: "int"
                  symmetric: true
                  strategy: "channel"
                  actorder: False
              targets: ["Linear"]
